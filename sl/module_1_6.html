
<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/html">
  <head>
    <meta charset="utf-8">
    <title>MODUL 6: DOBA ALGORITMOV</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="This course is designed to help individuals to become smart consumers of news and informed participants in civic life.">
    <meta name="author" content="ESSENTIAL Project Turkish Team">

    <!-- Le styles -->
    <link href="../css/bootstrap.css" rel="stylesheet">
    <link href="http://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/themes/black-tie/jquery-ui.css" rel="stylesheet">
    <link href="../css/jquery.tocify.css" rel="stylesheet">
    <link href="../css/prettify.css" type="text/css" rel="stylesheet" />

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le fav icon -->
    <link rel="shortcut icon" href="../assets/ico/favicon.ico">

    <style>
    body {
      padding-top: 20px;
    }
    p {
      font-size: 16px;
    }
    .headerDoc {
      color: #005580;
    }

@media (max-width: 767px) {
    #toc {
        position: relative;
        width: 100%;
        margin: 0px 0px 20px 0px;
    }
}
    </style>

	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-VFJPMP12NF"></script>
	<script>
  		window.dataLayer = window.dataLayer || [];
  		function gtag(){dataLayer.push(arguments);}
 		gtag('js', new Date());

 		gtag('config', 'G-VFJPMP12NF');
	</script>

</head>

  <body>

    <div class="container-fluid">
      <div class="row-fluid">
        <div class="span3">
          <div id="toc">
            <center>
              <br>
              <code class="trainee">Trainees Edition</code>
              <code class="trainer">Trainers Edition</code>
              <code class="select"><a href="?userType=trainee">Trainees Edition</a></code>
              <code class="select"><a href="?userType=trainer">Trainers Edition</a></code>
            <a href="#top"><img src="../img/index/essential_logo.jpg" width="75%"></a>
            <p><a class="btn btn-secondary btn-small" href="index.html">MOOC HOME</a></p>
            </center>
          </div><!--/.well -->
        </div><!--/span-->

        <div class="span9">
          <div class="hero-unit">
            <h1>MODUL 6: DOBA ALGORITMOV</h1>
          </div>
          <h2>Opis modula</h2>
          <p>Glavni namen tega modula je ozaveščanje o algoritmih, njihovem delovanju in vplivu na ljudi in družbo ter o prednostih in posledicah avtomatiziranega odločanja.</p>
          <p class="trainer">The secondary aim is to guide trainers who want to use the content of this Module to train their trainees.</p>
          <p class="trainer">With these aims in this module, how algorithms work, their possible impact on people, societies and daily life, why they need to be approached and used by caution along with guidelines about how to teach the subject are covered.</p>
          <p>Sekundarni namen je usmerjati izvajalce usposabljanja, ki želijo vsebino tega modula uporabiti pri usposabljanju svojih udeležencev.</p>
          <p>S temi cilji je v tem modulu zajeto, kako algoritmi delujejo, kakšen je njihov morebitni vpliv na ljudi, družbe in vsakdanje življenje, zakaj je treba k njim pristopiti in jih uporabljati previdno, skupaj s smernicami o tem, kako poučevati to temo.</p>
          <p>Udeleženci, ki bodo uspešno zaključili ta modul, bodo znali:</p>
          <ul>
          <li>pokazati razumevanje, kaj so algoritmi in kako delujejo</li>
          <li>razumeti, kako algoritmi vplivajo na ljudi in družbe</li>
          <li>pokazati razumevanje prednosti in slabosti algoritmov</li>
          <li>pokazati razumevanje povezave med algoritmi, novicami in informativnimi viri</li>
          <li>pokazati razumevanje filtrirnih mehurčkov in odmevnih komor</li>
          </ul>
          <p>Poleg tega bodo izvajalci usposabljanj, ki bodo uspešno zaključili ta modul, lahko pokazali razumevanje smernic za usposabljanje na to temo.</p>
          <p class="trainer">Additionally, trainers who successfully complete this module, will be able to demonstrate an understanding of the guidelines for training on the subject.</p>
          <h2>Struktura modula</h2>
          <p>Ta modul je sestavljen iz naslednjih delov:</p>
            <ul>
            <li>Opis modula (cilji, opis vsebine in učni rezultati)</li>
            <li>Struktura modula</li>
            <li>Smernice za udeležence</li>
            <li class="trainer">Guidelines for Trainers (how to get prepared, methods to use and tips for trainers)</li>
            <li>Smernice za izvajalce usposabljanja (kako se pripraviti, metode za uporabo in nasveti za izvajalce usposabljanja)</li>
            <li>Vsebina (študijsko gradivo in vaje)</li>
            <li>Kviz</li>
            <li>Viri (reference in priporočeni viri ter videoposnetki)</li>
            </ul>
            <p>Glavni cilji modula, opis vsebine in učni rezultati so pojasnjeni v delu Opis modula. Vsebina vključuje vsa študijska gradiva in vaje, povezane z vsebino. Kviz vključuje vprašanja z več izbirami, s katerimi lahko udeleženci usposabljanja preverijo svoj napredek. Gradiva imajo dve komponenti: reference in priporočena gradiva za nadaljnji študij. Reference so seznam virov, navedenih v vsebinskem delu. Priporočeni viri so sestavljeni iz seznama dodatnih virov in videoposnetkov, ki jih je zelo priporočljivo prebrati in pogledati za nadaljnje učenje o temi. Smernice za udeležence izobraževanja vključujejo navodila in predloge za udeležence izobraževanja. Smernice za izvajalce usposabljanja vodijo izvajalce usposabljanja skozi različne faze usposabljanja in vsebujejo nasvete, ki bi lahko bili koristni pri poučevanju teme.</p>
          <h2>Smernice za udeležence usposabljanja</h2>
          <p>Od udeležencev izobraževanja se pričakuje, da bodo prebrali besedilo, si ogledali priporočene videoposnetke in izvedli vaje. Za dodatne informacije lahko poiščejo predlagane vire. Po končanem študiju vsebine učencem priporočamo, da opravijo kviz za oceno svojega napredka. Po potrebi lahko ponovno pregledajo študijsko gradivo.</p>
          <h2 class="trainer">Guidelines for Trainers</h2>
          <p class="trainer">Guidelines for trainers includes suggestions and tips for trainers about how to use the content of this Module to train people on the algorithms, the potential they have to affect people, their decisions and societies.</p>
          <span class="trainer">
          <h3>Getting Prepared</h3>
          <p>Preparing a presentation (PowerPoint/Prezi/Canva) which is supported with some visual materials which displays the results of search engine searches by different people or from different locations is strongly suggested. Alternatively a real time demonstration can be planned.</p>
          <h3>Getting Started</h3>
          <p>A short Kviz (3 to 5 questions) in Kahoot or questions with Mentimeter can be used at the beginning for engaging participants in the topic. It can be used as a motivation tool as well as a tool to check trainees&rsquo; existing knowledge about the subject.</p>
          <h3>Methods to Use</h3>
          <p>Various teaching methods can be used in combination during the training. Such as:</p>
          <ul>
          <li>Lecturing</li>
          <li>Discussion</li>
          <li>Group work</li>
          <li>Self reflection</li>
          </ul>
          <h3>Tips for Trainers      </h3>
          <h4>Warming-up</h4>
          <p>An effective way of involving participants and setting common expectations about what they will learn is to ask a few preliminary questions on the subject. This can be done through group work by asking trainees to discuss and collect ideas, but also individually by asking each participant to write their ideas on sticky notes.</p>
          <p>The activity can be conducted as follows:</p>
          <ul>
          <li>Ask trainees what they think about the place of algorithms in their daily life</li>
          <li>Ask trainees to classify the given examples and make a list of places/circumstances decisions are taken by algorithm</li>
          <li>Ask trainees whether algorithms have anything to do with the news we are exposed</li>
          <li>Ask trainees who writes this algorithms and sets the decision making rules/parametresAfter the discussions, making sure that trainees are able to understand algorithms are everywhere in our daily lives and they are written by other people and have a potential for manipulation.</li>
          </ul>
          <h4>Presenting the Objective of the Lesson</h4>
          <p>The objective of the lesson should be made clear (which is to raise awareness about algorithms, their place in daily life and their potential for manipulation). Following the warming-up question it will be easier to clarify the objectives.</p>
          <h4>Presenting the Lesson Content</h4>
          <p>While presenting the content make sure to interact with the trainees and encourage them for active participation.</p>
          <ul>
          <li>Before providing a definition of algorithm, ask participants to define it elaborate on its functions.</li>
          <li>Before providing an overview of the benefits and potential risks of algorithms, ask participants to elaborate on it.</li>
          <li>When talking about the differing results for the same search (by different people or location) from search engines, either support your claim with screen shuts or make a real time demonstration</li>
          <li>If time and facilities allow, ask participants to perform the same search and compare results.</li>
          <li>Make the connection between algorithms and news/news feeds clear</li>
          <li>After completing a comprehensive overview of the algorithms, filter bubbles and echo chambers, ask participants to elaborate on the role algorithms play in the spread of misinformation.</li>
          </ul>
          <h4>Concluding</h4>
          <p>Make a short summary of the lesson and ask a couple of questions which underline the most important messages you planned to give.</p>
          <ul>
          <li>Ask trainees whether being aware of the algorithms helps them to take control.</li>
          </ul>
          <p>After the discussions make sure that trainees understand that algorithms are making decisions for us and there is a room for manipulation.</p>
          </span>
          <h2>Vsebina: Doba algoritmov</h2>
          <h3>Uvod</h3>
          <p>Algoritem je skupek navodil in pravil, ki jih računalniki uporabljajo za reševanje problema ali izvajanje naloge (Head, Fister in MacMillan, 2020, str. 49). Algoritem lahko razumemo kot mini navodila, ki računalnikom povedo, kako naj opravijo določeno nalogo ali obdelujejo dane podatke (What is an algorithm?, n.d.)</p>
          <p>Algoritmi skrbijo za vsebino s prednostnim razvrščanjem, klasifikacijo, asociiranjem in filtriranjem informacij. Prednostno razvrščanje vsebine omogoča, da se pozornost nameni eni stvari na račun druge. Klasifikacija vključuje razvrstitev določene entitete kot sestavine določenega razreda z upoštevanjem poljubnega števila značilnosti te entitete. Asociacija označuje odnose med entitetami. Filtriranje pa vključuje vključitev ali izključitev določenih informacij na podlagi niza meril (Diakopoulos, 2013, str. 4-8). </p>
          <p>Algoritmi za filtriranje pogosto upoštevajo odločitve o prednostnem razvrščanju, klasifikaciji in asociaciji. Na primer, v aplikacijah za personalizacijo novic se novice filtrirajo glede na to, kako so bile te novice razvrščene, kako so bile povezane z interesi osebe in kako so bile prednostno razvrščene za to osebo. Na podlagi odločitev o filtriranju so nekatere informacije preveč poudarjene, druge pa cenzurirane (Diakopoulos, 2013, str. 4-8). </p>
          <p>"Doba algoritmov" je močno vplivala na družbo, politiko in novice. Algoritmi so močni, učinkoviti in pogosto vprašljivi dejavniki inovacij in družbenih sprememb (Head, Fister in MacMillan, 2020, str. 4). Danes so vse bolj izpopolnjeni algoritmi zasnovani tako, da pomagajo in včasih popolnoma nadomestijo človekovo posredovanje pri nalogah odločanja. Zdi se, da vse to opravijo z nižjimi stroški in večjo učinkovitostjo kot človeški napori (O'Neil, 2016). Potencialne koristi avtomatiziranega odločanja so neštete in jasne, hkrati pa obstajajo tudi nekatera tveganja in pomisleki (Olhede & Wolfe, 2019, str. 2).</p>
          <p>Obsežna razpoložljivost podatkov skupaj s hitrim tehnološkim napredkom na področju algoritmov izrazito spreminja družbo (Olhede & Wolfe, 2019, str. 2). V vsakdanjem življenju se algoritmi pogosto uporabljajo za vplivanje na odločitve o tem, kaj ljudje gledajo, kaj kupujejo (Head, Fister in MacMillan, 2020, str. 5), in celo, kako volijo (Epstein & Robertson, 2015). Algoritmi filtrirajo rezultate iskanja v brskalnikih. Lahko so programirani za odločanje o tem, kdo bo povabljen na razgovor za službo in na koncu, kdo bo dobil ponudbo za delo. Uporabljajo se lahko za upravljanje socialnih storitev, kot sta socialno varstvo in javna varnost. Lahko priporočajo, kateri prosilci za posojilo so dobro kreditno tveganje. Te nevidne črte kode lahko postavljajo medicinske diagnoze in lahko celo določijo dolžino prestajanja kazni (Head, Fister in MacMillan, 2020, str. 4-5).</p>
          <p>Algoritmi sprejemajo vplivne odločitve, ki teoretično lahko ter v praksi dejansko tudi povečajo moč podjetij in vlad (Diakopoulos, 2013, str. 29). Pri sprejemanju odločitev lahko algoritmi spodbujajo politično, gospodarsko, geografsko, rasno ali drugo diskriminacijo, na primer pri zdravstveni oskrbi, ocenjevanju kreditov in trgovanju z vrednostnimi papirji (Pasquale, 2011). Algoritmi imajo moč, da oblikujejo izkušnje uporabnikov in celo njihovo dojemanje sveta (Diakopoulos, 2013, str. 3). Kljub dejstvu, da lahko njihovo delovanje včasih povzroči nepravičnost in da lahko oblikujejo predstavo ljudi ter vplivajo na njihove odločitve, se ljudje pogosto ne zavedajo njihove prisotnosti, saj so nevidni.</p>
          <p>Algoritmična moč ni nujno škodljiva za ljudi, temveč lahko deluje tudi kot pozitivna sila (Diakopoulos, 2013, str. 2). Algoritmi po svoji naravi namreč niso ne dobri ne slabi. Njihovi učinki so prej odvisni od tega, za kaj so programirani, kdo izvaja programiranje, kako algoritmi delujejo v praksi, kako uporabniki komunicirajo z njimi in kaj se naredi z ogromno količino osebnih podatkov, s katerimi se hranijo (Head, Fister in MacMillan, 2020, str. 4). Vendar se je treba zavedati, da delujejo s pristranskostjo in da lahko delajo napake. Težava je pomanjkanje jasnosti glede tega, kako algoritmi izvajajo svojo moč nad ljudmi. Algoritmične kode so nepregledne (netransparentne) in skrite za plastmi tehnične zapletenosti (Diakopoulos, 2013, str. 2).</p>
          <p>Njihovi učinki so pomembni (Barocas, Hood in Ziewitz, 2013; Hamilton, Karahalios, Sandvig in Eslami, 2014; Sandvig, Hamilton, Karahalios in Langbort, 2014). Iskalni algoritmi na primer strukturirajo spletne informacije, ki so na voljo družbi, in lahko delujejo kot vratar (Granka, 2010, str. 364-365; Introna in Nissenbaum, 2000). Rezultati iskanja, ki jih spletni brskalnik zagotavlja svojim uporabnikom, imajo velik vpliv na to, kako vsak uporabnik gleda na splet (Xing, Meng, Doozan, Feamster, Lee in Snoeren, 2014). Raziskovalci so preizkusili učinek prilagojenih rezultatov iskanja na Googlu in ugotovili, da se rezultati razlikujejo glede na več dejavnikov, kot so spletna vsebina v danem trenutku, regija, iz katere se izvaja iskanje, nedavna zgodovina iskanja in koliko manipulacije iskalnika je bilo izvedene za favoriziranje določenega rezultata (Xing , Meng, Doozan, Feamster, Lee & Snoeren, 2014).</p>
          <center>
                <p><img src="../img/module_06/figure_02.jpg"></p>
                <p>Vir: <a target="_blank" href="https://www.digifloor.com/google-search-result-shows-different-ui-india-us-30">Gohel, 2013</a></p>
          </center>
          <p>Raziskave so pokazale, da imajo uvrstitve rezultatov iskanja, ki jih zagotavljajo podjetja, ki se ukvarjajo z brskalniki, velik vpliv na stališča, preference in vedenje potrošnikov. Uvrstitve spletnih iskalnikov pomembno vplivajo na odločitve potrošnikov, predvsem zato, ker uporabniki bolj zaupajo in izbirajo višje uvrščene rezultate kot nižje uvrščene. Zaradi očitne moči iskalnih lestvic so raziskovalci proučevali, ali bi jih bilo mogoče manipulirati, da bi spremenili preference neodločenih volivcev na demokratičnih volitvah. Ugotovitve kažejo, da lahko pristranske iskalne lestvice spremenijo volilne preference neodločenih volivcev za 20 % ali več, pri nekaterih demografskih skupinah je lahko ta sprememba veliko večja, takšne lestvice pa je mogoče prikriti, tako da se ljudje manipulacije ne zavedajo (Epstein in Robertson, 2015).</p>
          <p>Splošno razširjeno je napačno prepričanje, da so algoritmi (kot matematični modeli) in njihovi rezultati pošteni, objektivni in nepristranski (O'Neil, 2016). Ker algoritme obdelujejo računalniki in sledijo logičnim navodilom, ljudje pogosto mislijo, da so nevtralni ali brez vrednot, vendar lahko odločitve, ki jih sprejmejo ljudje pri oblikovanju in prilagajanju algoritma, ter podatki, na katerih se algoritem usposablja, vnašajo človeške pristranskosti, ki se lahko pri velikem obsegu še povečajo (Head, Fister in MacMillan, 2020, str. 49). Algoritmi prav tako uporabljajo slabe približke za povzemanje človeškega vedenja in izpisovanje rezultatov. Uporaba slabih približkov za merjenje in povzemanje realnosti je lahko pogosto diskriminatorne narave. Algoritmi sprejemajo odločitve, ne da bi jim bilo treba pojasniti, kako so do njih prišli (O'Neil, 2016). Nasprotno pa v primeru človeškega odločevalca obstaja povratna zanka, ki omogoča popravljanje napak v presoji (O'Neil, 2016). Poleg tega algoritmi, ki jih družbena spletišča uporabljajo za promocijo vsebin, ne ocenjujejo veljavnosti vsebin, zaradi česar se lahko širijo in so se širile napačne informacije (Jolly, 2014).</p>
          <p>Kot zaključek lahko rečemo, da bodo algoritmi ostali, vendar jih je treba uporabljati previdno (O'Neil, 2016).</p>
          <h3>Življenje v dobi algoritmov: širša slika</h3>
          <p>Svet informacij se je v zadnjem desetletju nepričakovano spremenil – te spremembe je mogoče deloma pojasniti z vplivom algoritmov. Nekateri dejavniki, ki so gonilo teh sprememb, nam pomagajo videti širšo sliko, ki jo Head, Fister in MacMillan (2020, str. 5-7) povzemajo na naslednji način:</p>
          <ol>
          <li>Zbiranje podatkov o našem vsakdanjem življenju poteka nevidno in nenehno.</li>
          <li>Napredek v znanosti o podatkih omogoča sistemom zbiranje in obdelavo podatkov v realnem času, hitro in v velikem obsegu ("veliki podatki"). </li>
          <li>Podatki, zbrani iz številnih virov, se hitro povezujejo.</li>
          <li>Avtomatizirani sistemi odločanja se uporabljajo v družbenih institucijah in procesih, ki določajo stvari, kot so: kdo dobi službo, hipoteko ali posojilo, dostop do socialnih storitev, sprejem v šolo ali izobraževalne storitve.</li>
          <li>Strojno učenje in umetna inteligenca, ki se vse pogosteje uporabljata v programskih izdelkih, ki sprejemajo zelo pomembne odločitve, se pogosto opirata na pristranske ali nepopolne nabore podatkov.</li>
          <li>Zaradi razdrobljenosti objavljenih informacij in njihove porazdelitve prek iskalnih platform in platform družbenih medijev je ocenjevanje nekoč ločenih virov (npr. znanstvenih člankov, časopisnih zgodb) težje.</li>
          <li>Profitne panoge zbirajo podatke o interakciji ljudi z računalniki za personalizacijo rezultatov, napovedovanje in usmerjanje vedenja, ciljno oglaševanje, politično prepričevanje in družbeno vedenje v velikem obsegu.</li>
          <li>Zdi se, da imajo te panoge težave s predvidevanjem ali odzivanjem na nenamerne posledice.</li>
          <li>Razmah platform družbenih medijev, ki nimajo etičnega kodeksa, prispeva k nezaupanju v uveljavljene tradicije znanja, kot sta novinarstvo in štipendiranje.</li>
          <li>Tehnična infrastruktura, ki vpliva na to, kako ljudje pridobivajo informacije ter oblikuje njihovo znanje in prepričanja, je po svoji zasnovi javnosti večinoma nevidna.</li>
          <li>Javnost premalo ve, kdo ima moč nad informacijskimi sistemi in njihovimi algoritmi ter kako se ta moč uporablja. </li>
          </ol>
          <p>Zato je razumevanje delovanja informacij v dobi algoritmov za posameznike izjemnega pomena (Head, Fister in MacMillan, 2020, str. 7-8).</p>
          <center>
                <p><img src="../img/module_06/figure_04.jpg"></p>
                <p>Vir: <a target="_blank" href="https://www.projectinfolit.org/uploads/2/7/5/4/27541717/algoreport.pdf">Head, Fister &amp; MacMillan, 2020</a>, p. 6.</p>
          </center>
          <h3>Novice, informativni tokovi in algoritmi</h3>
          <p>Algoritmi se med drugim pogosto uporabljajo tudi za filtriranje novic o svetu. Danes bralci novice vse pogosteje odkrivajo prek družbenih medijev, e-pošte in aplikacij za branje, zato se promet na domačih straneh novičarskih spletnih mest še naprej zmanjšuje. Založniki se tega dobro zavedajo, zato so ustrezno prilagodili svojo infrastrukturo in zgradili algoritme, ki spreminjajo izkušnjo spletnega mesta glede na to, od kod bralec vstopi. Posledično ljudje zelo verjetno vidijo različne prve strani časopisov na spletu, saj so prilagojene posameznikom. Čeprav založniki menijo, da je optimizacija spletnih mest za bralne in delitvene preference določenih spletnih občinstev dobra stvar, saj tako uporabniki hitro in učinkovito pridejo do vsebine, ki jih bo verjetno zanimala, pa tovrstna oskrba morda ni dobra za bralce (Jolly, 2014).</p>
          <p>Kanali novic, ki uporabnikom zagotavljajo pogosto posodobljene novice, so še ena aplikacija, pri kateri imajo algoritmi vplivno vlogo. Na primer Facebook novičarski kanal prikazuje algoritmično izbran ali filtriran seznam zgodb, izbranih iz nabora vseh zgodb, ki jih je ustvarilo omrežje prijateljev (Eslami, Rickman, Vaccaro, Aleyasen, Vuong, Karahalios, Hamilton in Sandvig, 2015, str. 153). Raziskava, opravljena med uporabniki Facebooka, s katero so preverjali njihovo dojemanje algoritma za izbiro novic na Facebooku, je pokazala, da se več kot polovica udeležencev (62,5 %) sploh ni zavedala obstoja algoritma za izbiro novic na Facebooku. Menili so, da se je v njihovem novičarskem kanalu pojavila vsaka posamezna zgodba njihovih prijateljev in strani, ki jim sledijo (Eslami, Rickman, Vaccaro, Aleyasen, Vuong, Karahalios, Hamilton in Sandvig, 2015, str. 153).</p>
          <center>
                <p><img src="../img/module_06/figure_03.jpg" width="50%"></p>
                <p><a target="_blank" href="https://pixnio.com/media/movie-video-recording-filming-street-television-news">avtorja Bicanski</a></p>
          </center>
          <p>Algoritmi ljudem ne olajšajo le iskanja vsebine, ki jih zanima, temveč tudi iskanja vsebine, za katero algoritem meni, da jih zanima. Diakopoulos (2013, str. 2) trdi, da so danes algoritmi, ki jih poganjajo ogromne količine podatkov, novi nosilci moči v družbi.</p>
          <h3>Filtrirni mehurčki</h3>
          <p>Filtrirni mehurček je intelektualna izolacija, do katere pride zaradi personalizacije, ki omogoča izogibanje izpostavljenosti informacijam, ki so v nasprotju s predhodnim znanjem in mnenji. Nastane kot rezultat obdelave informacij, povezanih z uporabnikom (kot so zgodovina brskanja in iskanja, lokacija ter kanali družbenih medijev). Družbeni mediji lahko z algoritmi, ki jih uporabljajo, uporabnike zlahka zaprejo v filtrirne mehurčke. Medtem ko filtrirni mehurčki obkrožajo uporabnike s podobno mislečimi ljudmi, ki širijo informacije, skladne z njihovimi obstoječimi prepričanji in mnenji, lahko povzročijo manj stikov z ljudmi, ki imajo nasprotujoča si stališča. Prilagojeni rezultati iskanja pri Googlu in prilagojeni tokovi novic pri Facebooku sta dva primera, ki potrjujeta ta pojav (Filter bubble, 2018; Cooke, 2018).</p>
          <p>Po besedah Pariserja, avtorja tega izraza, je filtrirni mehurček svet, ki je nastal s prehodom od "človeških vratarjev", kot so uredniki časopisov, ki skrbijo za pomembnost tistega, kar se znajde na prvi strani, k algoritemskim, ki jih uporabljata Facebook in Google, ki predstavita vsebino, za katero menita, da jo bo uporabnik najverjetneje kliknil (Fitts, n.d.). Tehnološka podjetja so komercialni subjekti, zato morajo za zadovoljstvo svojih delničarjev spodbujati uporabnike, da čim dlje ostanejo na njihovem spletnem mestu, da bi čim bolj povečali število izpostavljenosti oglasom. To storijo tako, da prilagodijo algoritme, da zagotovijo več tistega, kar je bilo uporabnikom v preteklosti všeč, kar so delili ali komentirali (Wardle in Derakhshan, 2017, str. 52). To novo digitalno vesolje je "prijeten kraj, ki ga naseljujejo uporabnikovi najljubši ljudje, stvari in ideje" (Fitts, n.d.). Vendar ta selektivna izpostavljenost informacijam ne povzroča skrbi le zaradi svojih kognitivnih vidikov, temveč tudi zaradi moralnih, političnih in družbenih vidikov (Cisek in Krakowska, 2018).</p>
          <center>
                <p><img src="../img/module_06/figure_01.jpg" width="50%"></p>
                <p><a target="_blank" href="https://commons.wikimedia.org/wiki/File:FilterBubble.jpg">Filter bubble avtorja </a><a target="_blank" href="https://commons.wikimedia.org/w/index.php?title=User:Evbestie&amp;action=edit&amp;redlink=1">Evbestie</a> <a target="_blank" href="https://commons.wikimedia.org/wiki/File:FilterBubble.jpg">je licenciran pod CC</a></p>
          </center>
          <p>Personalizacija nedvomno pomaga v boju proti informacijskemu kaosu in preobremenjenosti z informacijami, saj olajša dostop do ustreznih, koristnih informacij in preprečuje ostale (nepomembne, neuporabne, dražljive itd.). Vendar obstaja pomembna razlika med samoizbrano personalizacijo in vnaprej izbrano personalizacijo. Pri vnaprej izbrani personalizaciji algoritmi izberejo vsebino za uporabnike, medtem ko pri samoizbrani personalizaciji ljudje izberejo in odločijo, katero vsebino želijo videti. To seveda ni nič novega. Ljudje so vedno (in še vedno) doživljali filtrirne mehurčke, ker so vedno obstajali/obstajajo informacijski vratarji (kot so starši, vlade, religije, družbene skupine), vendar so resne skrbi, kadar so ti mehurčki nevidni in neprostovoljni. Kadar ljudje ne vedo, da so informacije, ki jih dobijo, personalizirane, lahko domnevajo, da so popolne in objektivne. Algoritmi kot vratarji (z drugimi besedami, mehanizmi cenzure) lahko ovirajo dostop do vsebine in zavedanje, da obstajajo tudi drugačna stališča. Najhuje pa je, da ne temeljijo na etičnih načelih (Cisek in Krakowska, 2018). Vrednosti filtrov ni mogoče zanikati, vendar pa je potencial, ki ga imajo, da pustijo ljudi slepe za ideje ali dogodke, precej zaskrbljujoč (Anderson, 2016).</p>
          <p>Negativne vidike filtrirnih mehurčkov Cisek in Krakowska (2018) povzemata na naslednji način: "ustvarjanje zavajajoče in napačne podobe resničnosti, individualnega mentalnega modela; zapiranje v omejen, hermetičen krog informacij, mnenj, stališč, svetovnih nazorov, kar omejuje pridobivanje znanja; potrjevanje pristranskosti in oblikovanje kognitivnih predsodkov; spodbujanje intelektualne in čustvene lenobe."</p>
          <p>Razbijanje filtrirnih mehurčkov je mogoče najprej z zavedanjem, da filtrirni mehurčki obstajajo, nato pa z razvijanjem veščin kritičnega mišljenja in informacijske pismenosti. Cisek in Krakowska (2018) navajata naslednje predloge za razbijanje filtrirnih mehurčkov: aktivno iskanje informacij namesto pasivnega uživanja informacij, ki so jih izbrali algoritmi; uporaba prednosti naprednih iskalnih orodij, ki jih ponujajo brskalniki (logični izrazi, ukazi, besedne zveze, napredno iskanje itd.); uporaba različnih iskalnikov in primerjava rezultatov; uporaba iskalnikov, ki ne sledijo uporabnikom in ne personalizirajo (kot so DuckDuckGo, Qwant, StartPage); uporaba programske opreme, ki pomaga izstopiti iz filtrirnih mehurčkov (kot so Escape Your Bubble, FleepFeed, Pop Your Bubble) in tudi upoštevanje, da obstaja globoki splet (angl. Deep Web).</p>
          <p>Wardle in Derakhshan (2017) pravita, da je "največji izziv filtrirnih mehurčkov ponovno usposobiti naše možgane" in naučiti ljudi "iskati alternativne poglede". Kajti če/ko se zavedamo, da ljudje iščejo in uživajo vsebine iz številnih drugih razlogov, ne samo zaradi informiranosti (kot je občutek povezanosti s podobnimi ljudmi ali pripadnost določeni identiteti), to pomeni, da je za prebijanje filtrirnih mehurčkov potrebno več kot samo zagotavljanje različnih informacij.</p>
          <h3>Odmevne komore</h3>
          <p>Odmevna komora je v medijih metaforičen opis razmer, v katerih se prepričanja okrepijo zaradi ponavljajoče se komunikacije znotraj zaprtega sistema. V odmevni komori se ljudje soočajo z informacijami, ki krepijo njihova obstoječa prepričanja in stališča. To lahko razumemo kot nezavedno izvajanje potrditvene pristranskosti, ki lahko poveča politično in družbeno polarizacijo ter ekstremizem (Echo chamber, 2020).</p>
          <p>Odmevne komore in filtrirni mehurčki sta dva tesno povezana pojma, ki se na splošno uporabljata izmenično. Vendar se "odmevna komora nanaša na splošni pojav, pri katerem so posamezniki izpostavljeni le informacijam podobno mislečih posameznikov, medtem ko so filtrirni mehurčki posledica algoritmov, ki izbirajo vsebine na podlagi predhodnega spletnega vedenja" (Echo chamber, 2020). Z drugimi besedami, filtrirni mehurčki prispevajo k ustvarjanju odmevnih komor, ki imajo zagotovo politične in družbene posledice.</p>
          <center>
                <p><img src="../img/module_06/figure_05.jpg" width="50%"></p>
                <p><a target="_blank" href="https://www.flickr.com/photos/28648431@N00/239657074">"crop circle - echoes"</a> avtorja <a target="_blank" href="https://www.flickr.com/photos/28648431@N00">oddsock</a> je licenciran pod <a target="_blank" href="https://creativecommons.org/licenses/by/2.0/?ref=ccsearch&amp;atype=rich">CC BY 2.0</a></p>
          </center>
          <p>Odmevne komore zagotavljajo varen prostor za izmenjavo prepričanj in svetovnih nazorov z drugimi brez strahu pred konfrontacijo ali delitvijo (Wardle in Derakhshan, 2017). Agenti, ki ustvarjajo napačne informacije, ciljajo na skupine znotraj odmevnih komor, "za katere vedo, da bodo bolj dovzetne za sporočilo" in da tam "ne bo nikogar, ki bi izpodbijal ideje. Zelo verjetno je, da bo sporočilo nato delil prvotni prejemnik" (Wardle in Derakhshan, 2017). "Kot kažejo raziskave, je veliko bolj verjetno, da bodo ljudje zaupali sporočilu, ki prihaja od nekoga, ki ga poznajo" (Metzger, Flanagin in Medders, 2010). Zato se lahko napačne informacije širijo tako hitro. Potuje med omrežji znancev, kjer je zaupanje običajno visoko. Temeljna težava je, da filtrirni mehurčki poslabšajo polarizacijo, saj ljudem omogočajo, da živijo v lastnih spletnih odmevnih komorah, in jim puščajo na voljo le mnenja, ki potrjujejo njihove lastne ideje, namesto da bi jih spodbijala (Wardle in Derakhshan, 2017).</p>
        <p>Za obema pojavoma stoji teorija ponavljanja, ki omogoča delovanje lažnih novic, kot so v študiji iz leta 2012 poudarili raziskovalci z univerze Central Washington. Psihologinja Lynn Hasher z Univerze v Torontu trdi, da se "zaradi ponavljanja stvari zdijo bolj verjetne", "učinek pa je verjetno močnejši, ko so ljudje utrujeni ali jih motijo druge informacije" (Dreyfuss, 2017).</p>
          <h2>Vaje</h2>
          <h3>Vaja 1</h3>
          <iframe src="https://essential.bilgiyonetimi.net/wp-admin/admin-ajax.php?action=h5p_embed&id=119" width="936" height="342" frameborder="0" allowfullscreen="allowfullscreen" title="SLO Essential MOOC: Part 1 - Module 6 - Exercise 1"></iframe><script src="https://essential.bilgiyonetimi.net/wp-content/plugins/h5p/h5p-php-library/js/h5p-resizer.js" charset="UTF-8"></script>
          <h3>Vaja 2</h3>
          <p><iframe src="https://essential.bilgiyonetimi.net/wp-admin/admin-ajax.php?action=h5p_embed&id=120" width="936" height="342" frameborder="0" allowfullscreen="allowfullscreen" title="SLO Essential MOOC: Part 1 - Module 6 - Exercise 2"></iframe><script src="https://essential.bilgiyonetimi.net/wp-content/plugins/h5p/h5p-php-library/js/h5p-resizer.js" charset="UTF-8"></script></p>
        <h2>Kviz</h2>
        <p><iframe src="https://essential.bilgiyonetimi.net/wp-admin/admin-ajax.php?action=h5p_embed&id=121" width="936" height="257" frameborder="0" allowfullscreen="allowfullscreen" title="SLO Essential MOOC: Part 1 - Module 5 - Quiz 1"></iframe><script src="https://essential.bilgiyonetimi.net/wp-content/plugins/h5p/h5p-php-library/js/h5p-resizer.js" charset="UTF-8"></script></p>
        <h2>Reference</h2>
        <p><a target="_blank" href="https://virtualcanuck.ca/2016/10/08/is-google-scholar-a-filter-bubble/">Anderson, T. (2016)</a>. Is Google Scholar a filter bubble?</p>
        <p><a target="_blank" href="http://www.realtechsupport.org/UB/ML+CT/papers/selected_papers/Ziewitz_GoverningAlgorithms_2013.pdf">Barocas, S., Hood, S., &amp; Ziewitz, M. (2013).</a> Governing algorithms: A provocation piece. In Governing Algorithms: A Conference on Computation, Automation, and Control.<a target="_blank" href="http://www.realtechsupport.org/UB/ML+CT/papers/selected_papers/Ziewitz_GoverningAlgorithms_2013.pdf"></a></p>
        <p><a target="_blank" href="https://www.researchgate.net/publication/328199698_The_filter_bubble_a_perspective_for_information_behaviour_research">Cisek, S. &amp; Krakowska, M. (2018). </a>The filter bubble: a perspective for information behaviour research. Paper presented at ISIC 2018 Conference.</p>
        <p><a target="_blank" href="https://literariness.org/wp-content/uploads/2019/06/Literariness.org-Nicole-A.-Cooke-Fake-News-and-Alternative-Facts_-Information-Literacy-in-a-Post-Truth-Era-ALA-Editions-2018.pdf">Cooke, N. (2018).</a> Fake news and alternative facts: Information literacy in a post-truth era. ALA.</p>
        <p><a target="_blank" href="https://academiccommons.columbia.edu/doi/10.7916/D8ZK5TW2">Diakopoulos, N. (2013).</a> Algorithmic Accountability Reporting: On the Investigation of Black Boxes. Tow Center for Digital Journalism.</p>
        <p><a target="_blank" href="https://www.wired.com/2017/02/dont-believe-lies-just-people-repeat/">Dreyfuss, E. (2017).</a> Want to make a lie seem true? Say it again. And again. And again. Wired.<a target="_blank" href="https://www.wired.com/2017/02/dont-believe-lies-just-people-repeat/"></a></p>
        <p><a target="_blank" href="https://en.wikipedia.org/wiki/Echo_chamber_(media)">Echo chamber (media). (2020).</a> In Wikipedia.</p>
        <p><a target="_blank" href="https://doi.org/10.1073/pnas.1419828112">Epstein, R. &amp; Robertson, R. E. (2015).</a> The search engine manipulation effect (SEME) and its possible impact on the outcomes of elections. In: Proceedings of the National Academy of Sciences 112 (33), E4512-E4521.</p>
        <p><a target="_blank" href="https://doi.org/10.1145/2702123.2702556">Eslami, M., Rickman, A.,Vaccaro, K., Aleyasen, A.,Vuong, A., Karahalios, K., Hamilton, K. &amp; Sandvig, C. (2015).</a> "I always assumed that I wasn't really that close to [her]": Reasoning about Invisible Algorithms in News Feeds. In:<a target="_blank" href="https://dl.acm.org/doi/proceedings/10.1145/2702123"> </a>CHI '15: Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (pp. 153&ndash;162).</p>
        <p><a target="_blank" href="https://www.techopedia.com/definition/28556/filter-bubble">Filter bubble. (2018)</a>. In Technopedia.</p>
        <p><a target="_blank" href="https://archives.cjr.org/feature/the_king_of_content.php?page=all">Fitts, A. S. (n.d.). </a>The king of content: How Upworthy aims to alter the Web, and could end up altering the world. Columbia Journalism Review. <a target="_blank" href="https://archives.cjr.org/feature/the_king_of_content.php?page=all"></a></p>
        <p><a target="_blank" href="https://www.digifloor.com/google-search-result-shows-different-ui-india-us-30">Gohel, J. (2013).</a> Google shows different UI in India and US.</p>
        <p><a target="_blank" href="https://www.csd.uoc.gr/~hy474/papers/PoliticsSearchDecadeRetrospective.pdf">Granka, L. A. (2010).</a> The Politics of Search: A Decade Retrospective. The Information Society, 26(5), 364&ndash;374.</p>
        <p><a target="_blank" href="https://dl.acm.org/doi/pdf/10.1145/2559206.2578883">Hamilton, K., Karahalios, K., Sandvig, C., &amp; Eslami, M. (2014).</a> A path to understanding the effects of algorithm awareness. In Proc. CHI EA 2014, ACM Press (2014), 631&ndash;642. <a target="_blank" href="https://dl.acm.org/doi/pdf/10.1145/2559206.2578883"></a></p>
        <p><a target="_blank" href="https://www.projectinfolit.org/%20uploads/2/7/5/4/27541717/algoreport.pdf">Head, A.J., Fister, B. &amp; MacMillan, M. (2020).</a> Information literacy in the age of algorithms: Student experiences with news and information, and the need for change. Project Information Research Institute.</p>
        <p><a target="_blank" href="https://www.researchgate.net/publication/2410076_Shaping_The_Web_Why_The_Politics_Of_Search_Engines_Matters">Introna, L., &amp; Nissenbaum, H. (2000).</a> Shaping the Web: Why the Politics of Search Engines Matters. The Information Society, 16 (3), 169-185.</p>
        <p><a target="_blank" href="https://archives.cjr.org/news_literacy/algorithms_filter_bubble.php">Jolly, J. (20 May 2014). </a>How algorithms decide the news you see: Past clicks affect future ones. Columbia Journalism Review.</p>
        <p><a target="_blank" href="https://mikekhorev.com/why-do-different-browsers-show-different-search-results-on-google">Khorev, M. (2016).</a> Why do different browsers and devices show different search results on Google?</p>
        <p><a target="_blank" href="https://onlinelibrary.wiley.com/doi/full/10.1111/j.1460-2466.2010.01488.x">Metzger, M.J., Flanagin, A.J. &amp; Medders, R.B. (2010)</a> Social and Heuristic Approaches to Credibility Evaluation Online. Journal of Communication, 60(3), 413-439.</p>
        <p><a target="_blank" href="http://governance40.com/wp-content/uploads/2019/03/Weapons-of-Math-Destruction-Cathy-ONeil.pdf">O&rsquo;Neil, C. (2016).</a> Weapons of math destruction: How big data increases inequality and threatens democracy. Crown Publishers.</p>
        <p><a target="_blank" href="https://doi.org/10.1098/rsta.2017.0364">Olhede, S.C. &amp; Wolfe, P. J. (2019).</a> The growing ubiquity of algorithms in society: Implication, impact and innovation. Philosophical Transactions of the Royal Society, 376 (128).</p>
        <p>Pariser, E. (2011). The Filter bubble: How the new personalized Web is changing what we read and how we think. Penguin Books.</p>
        <p><a target="_blank" href="https://ssrn.com/abstract=1762766">Pasquale, F. A. (2011).</a> Restoring Transparency to Automated Authority. Journal on Telecommunications and High Technology Law, 9(235).</p>
        <p><a target="_blank" href="http://social.cs.uiuc.edu/papers/pdfs/ICA2014-Sandvig.pdf">Sandvig, C., Hamilton, K., Karahalios, K., and Langbort, C. (2014).</a> Auditing algorithms: Research methods for detecting discrimination on internet platforms. In Data Discrimination: Converting Critical Concerns into Productive Inquiry.</p>
        <p><a target="_blank" href="https://rm.coe.int/information-disorder-toward-an-interdisciplinary-framework-for-researc/168076277c">Wardle, C. &amp; Derakhshan (2017).</a> Information disorder: Toward an interdisciplinary framework for research and policymaking. The Council of Europe. <a target="_blank" href="https://rm.coe.int/information-disorder-toward-an-interdisciplinary-framework-for-researc/168076277c"></a></p>
        <p><a target="_blank" href="https://www.thinkautomation.com/eli5/what-is-an-algorithm-an-in-a-nutshell-explanation/">What is an algorithm? An &lsquo;in a nutshell&rsquo; explanation. (n.d.)</a>. Think Automation.</p>
        <p><a target="_blank" href="https://doi.org/10.1007/978-3-319-04918-2_13">Xing X., Meng W., Doozan D., Feamster N., Lee W. &amp; Snoeren A.C. (2014).</a> Exposing Inconsistent Web Search Results with Bobble. In: Faloutsos M., Kuzmanovic A. (eds) Passive and Active Measurement. PAM 2014. Lecture Notes in Computer Science, vol 8362. Springer, Cham.<a target="_blank" href="https://doi.org/10.1007/978-3-319-04918-2_13"></a></p>
        <h2>Priporočeni viri</h2>
        <p><a target="_blank" href="https://literariness.org/wp-content/uploads/2019/06/Literariness.org-Nicole-A.-Cooke-Fake-News-and-Alternative-Facts_-Information-Literacy-in-a-Post-Truth-Era-ALA-Editions-2018.pdf">Cooke, N. (2018).</a> Fake news and alternative facts: Information literacy in a post-truth era. ALA.</p>
        <p><a target="_blank" href="https://academiccommons.columbia.edu/doi/10.7916/D8ZK5TW2">Diakopoulos, N. (2013).</a> Algorithmic Accountability Reporting: On the Investigation of Black Boxes. Tow Center for Digital Journalism.</p>
        <h2>Priporočeni videoposnetki</h2>
        <p><a target="_blank" href="https://www.youtube.com/watch?v=08bD-t-ZyfA&amp;t=88s">Khorev, M. (2017).</a> Why are my search results different than others&rsquo; search results?</p>
        <p><a target="_blank" href="https://www.youtube.com/watch?v=prx9bxzns3g">Praiser, E. (2018)</a>. How news feed algorithms superchange confirmation bias. Big Think.</p>
        <p><a target="_blank" href="https://www.youtube.com/watch?v=pT-k1kDIRnw">GCFLearnFree.org. (2018).</a> How filter bubbles isolate you.</p>
        <p><span id="docs-internal-guid-3b263a85-7fff-8c45-78ae-a78de6e60502"></span></p>
        <p><a target="_blank" href="https://www.youtube.com/watch?v=Se20RoB331w">GCFLearnFree.org. (2019).</a> What is an echo chamber?</p>
        </div><!--/span-->
      </div><!--/row-->

    </div><!--/.fluid-container-->

    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../js/jquery-1.8.3.min.js"></script>
    <script src="../js/jquery-ui-1.9.1.custom.min.js"></script>
    <script src="../js/bootstrap.bundle.min.js"></script>
    <script src="../js/jquery.tocify.js"></script>
    <script src="../js/prettify.js"></script>
    <script src="../js/user_control.js"></script>
    <script>
        $(function() {

            var toc = $("#toc").tocify({
              selectors: "h2,h3,h4,h5"
            }).data("toc-tocify");

            prettyPrint();
            $(".optionName").popover({ trigger: "hover" });

        });
    </script>

  </body>
</html>
